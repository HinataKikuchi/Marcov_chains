{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 32-bit ('.venv': venv)",
   "display_name": "Python 3.8.5 32-bit ('.venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "72fce3dea2b39fbfaf3ec333901b9c768a6445f500793a912d9bcad848fbbcd3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['__BEGIN__', 'おいしい', 'ビール'],\n",
       " ['おいしい', 'ビール', 'を'],\n",
       " ['ビール', 'を', '飲も'],\n",
       " ['を', '飲も', 'う'],\n",
       " ['飲も', 'う', '__END__']]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "# 開始、終端記号を設定する。\n",
    "BEGIN = '__BEGIN__'\n",
    "END = '__END__'\n",
    "# 実際に一文を3単語ずつに分けてみる。\n",
    "sentence = 'おいしいビールを飲もう'\n",
    "\n",
    "t = Tokenizer()\n",
    "# ここで型変換しないとgeneratorのリストができてしまう\n",
    "# 分かち書きした文章に開始終端記号を追加してリストにする\n",
    "words = list(t.tokenize(sentence, wakati=True))\n",
    "words = [BEGIN] + words + [END]\n",
    "\n",
    "three_words_list = []\n",
    "for i in range(len(words) - 2):\n",
    "    three_words_list.append(words[i:i + 3])\n",
    "three_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({('__BEGIN__', 'おいしい', 'ビール'): 2,\n",
       "         ('おいしい', 'ビール', 'を'): 1,\n",
       "         ('ビール', 'を', '飲も'): 2,\n",
       "         ('を', '飲も', 'う'): 2,\n",
       "         ('飲も', 'う', '__END__'): 2,\n",
       "         ('__BEGIN__', 'ビール', 'を'): 1,\n",
       "         ('おいしい', 'ビール', 'は'): 1,\n",
       "         ('ビール', 'は', '生'): 1,\n",
       "         ('は', '生', '__END__'): 1})"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_three_words_list(sentence):\n",
    "    \"\"\"文章を3単語の組にして返す\"\"\"\n",
    "    t = Tokenizer()\n",
    "    words = list(t.tokenize(sentence, wakati=True))\n",
    "    words = [BEGIN] + words + [END]\n",
    "    three_words_list = []\n",
    "    for i in range(len(words) - 2):\n",
    "        three_words_list.append(tuple(words[i:i+3]))\n",
    "    return three_words_list\n",
    "\n",
    "sentences = ['おいしいビールを飲もう', 'ビールを飲もう', 'おいしいビールは生']\n",
    "three_words_list = []\n",
    "for sentence in sentences:\n",
    "    three_words_list += get_three_words_list(sentence)\n",
    "three_words_count = Counter(three_words_list)\n",
    "three_words_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_marcov_dict(three_words_count):\n",
    "    \"\"\"マルコフ連鎖での文章作成用の辞書データを作成する\"\"\"\n",
    "    markov_dict = {}\n",
    "    for three_words, count in three_words_count.items():\n",
    "        two_words = three_words[:2]\n",
    "        next_words = three_words[2]\n",
    "        if two_words not in markov_dict:\n",
    "            markov_dict[two_words] = {'words': [], 'weights': []}\n",
    "        markov_dict[two_words]"
   ]
  }
 ]
}